{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 113)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset and put it in dfs dataframe\n",
    "dfs = [pd.read_csv('./CSV_FIles/user_' + user + '.csv') for user in ['a','b']]\n",
    "data = pd.concat(dfs, axis=0).sample(frac=1.0, random_state=123).reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>AF3 delta std</th>\n",
       "      <th>AF3 delta m</th>\n",
       "      <th>AF3 theta std</th>\n",
       "      <th>AF3 theta m</th>\n",
       "      <th>AF3 alpha std</th>\n",
       "      <th>AF3 alpha m</th>\n",
       "      <th>AF3 beta std</th>\n",
       "      <th>AF3 beta m</th>\n",
       "      <th>F7 delta std</th>\n",
       "      <th>...</th>\n",
       "      <th>F8 beta std</th>\n",
       "      <th>F8 beta m</th>\n",
       "      <th>AF4 delta std</th>\n",
       "      <th>AF4 delta m</th>\n",
       "      <th>AF4 theta std</th>\n",
       "      <th>AF4 theta m</th>\n",
       "      <th>AF4 alpha std</th>\n",
       "      <th>AF4 alpha m</th>\n",
       "      <th>AF4 beta std</th>\n",
       "      <th>AF4 beta m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3570.358043</td>\n",
       "      <td>2063.710533</td>\n",
       "      <td>0.456885</td>\n",
       "      <td>3.249995</td>\n",
       "      <td>0.904365</td>\n",
       "      <td>2.133026</td>\n",
       "      <td>2.139093</td>\n",
       "      <td>3.209357</td>\n",
       "      <td>3568.120212</td>\n",
       "      <td>...</td>\n",
       "      <td>28.690691</td>\n",
       "      <td>40.909131</td>\n",
       "      <td>3649.644216</td>\n",
       "      <td>2123.882552</td>\n",
       "      <td>6.433752</td>\n",
       "      <td>16.377331</td>\n",
       "      <td>12.937765</td>\n",
       "      <td>18.813944</td>\n",
       "      <td>33.382509</td>\n",
       "      <td>48.405477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3572.012160</td>\n",
       "      <td>2064.363908</td>\n",
       "      <td>1.276283</td>\n",
       "      <td>2.241194</td>\n",
       "      <td>0.817629</td>\n",
       "      <td>2.037404</td>\n",
       "      <td>3.483975</td>\n",
       "      <td>2.982528</td>\n",
       "      <td>3567.117078</td>\n",
       "      <td>...</td>\n",
       "      <td>68.654852</td>\n",
       "      <td>37.173007</td>\n",
       "      <td>3607.344422</td>\n",
       "      <td>2112.397644</td>\n",
       "      <td>10.002576</td>\n",
       "      <td>20.026195</td>\n",
       "      <td>4.766066</td>\n",
       "      <td>12.693254</td>\n",
       "      <td>80.381629</td>\n",
       "      <td>42.664033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3577.105212</td>\n",
       "      <td>2066.827754</td>\n",
       "      <td>0.934807</td>\n",
       "      <td>2.149105</td>\n",
       "      <td>0.307708</td>\n",
       "      <td>1.416313</td>\n",
       "      <td>1.622345</td>\n",
       "      <td>3.011557</td>\n",
       "      <td>3566.396533</td>\n",
       "      <td>...</td>\n",
       "      <td>19.997132</td>\n",
       "      <td>26.721568</td>\n",
       "      <td>3643.312676</td>\n",
       "      <td>2116.121387</td>\n",
       "      <td>3.414466</td>\n",
       "      <td>9.414864</td>\n",
       "      <td>6.781557</td>\n",
       "      <td>13.850787</td>\n",
       "      <td>25.237995</td>\n",
       "      <td>31.099147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3570.545677</td>\n",
       "      <td>2063.521648</td>\n",
       "      <td>1.498312</td>\n",
       "      <td>2.469780</td>\n",
       "      <td>0.672349</td>\n",
       "      <td>1.436351</td>\n",
       "      <td>1.690035</td>\n",
       "      <td>2.344049</td>\n",
       "      <td>3566.263726</td>\n",
       "      <td>...</td>\n",
       "      <td>1.933751</td>\n",
       "      <td>1.780409</td>\n",
       "      <td>3569.917242</td>\n",
       "      <td>2062.488143</td>\n",
       "      <td>1.718757</td>\n",
       "      <td>2.002083</td>\n",
       "      <td>0.722192</td>\n",
       "      <td>1.146630</td>\n",
       "      <td>1.221092</td>\n",
       "      <td>1.732873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3570.268998</td>\n",
       "      <td>2062.539180</td>\n",
       "      <td>1.192891</td>\n",
       "      <td>2.941243</td>\n",
       "      <td>0.585210</td>\n",
       "      <td>1.807655</td>\n",
       "      <td>1.773141</td>\n",
       "      <td>2.250589</td>\n",
       "      <td>3570.684256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990175</td>\n",
       "      <td>1.542020</td>\n",
       "      <td>3569.966082</td>\n",
       "      <td>2062.837023</td>\n",
       "      <td>0.546132</td>\n",
       "      <td>1.499412</td>\n",
       "      <td>0.965567</td>\n",
       "      <td>1.577828</td>\n",
       "      <td>1.143104</td>\n",
       "      <td>1.852612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3568.423670</td>\n",
       "      <td>2063.099248</td>\n",
       "      <td>1.897790</td>\n",
       "      <td>3.728823</td>\n",
       "      <td>1.304186</td>\n",
       "      <td>1.854353</td>\n",
       "      <td>1.366575</td>\n",
       "      <td>2.546458</td>\n",
       "      <td>3563.560922</td>\n",
       "      <td>...</td>\n",
       "      <td>36.551948</td>\n",
       "      <td>66.931186</td>\n",
       "      <td>3725.210509</td>\n",
       "      <td>2180.197439</td>\n",
       "      <td>8.820788</td>\n",
       "      <td>38.012788</td>\n",
       "      <td>19.601233</td>\n",
       "      <td>29.431054</td>\n",
       "      <td>38.559351</td>\n",
       "      <td>67.470041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3576.455470</td>\n",
       "      <td>2067.504612</td>\n",
       "      <td>0.819413</td>\n",
       "      <td>2.076764</td>\n",
       "      <td>0.262696</td>\n",
       "      <td>1.020132</td>\n",
       "      <td>2.796766</td>\n",
       "      <td>2.571867</td>\n",
       "      <td>3569.442445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147571</td>\n",
       "      <td>1.612922</td>\n",
       "      <td>3573.836239</td>\n",
       "      <td>2065.730532</td>\n",
       "      <td>0.662093</td>\n",
       "      <td>1.449532</td>\n",
       "      <td>0.325079</td>\n",
       "      <td>0.907729</td>\n",
       "      <td>1.947072</td>\n",
       "      <td>2.149902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3576.454303</td>\n",
       "      <td>2067.954953</td>\n",
       "      <td>0.882673</td>\n",
       "      <td>2.871386</td>\n",
       "      <td>0.642941</td>\n",
       "      <td>2.006386</td>\n",
       "      <td>1.854039</td>\n",
       "      <td>3.081949</td>\n",
       "      <td>3569.404934</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127120</td>\n",
       "      <td>2.103345</td>\n",
       "      <td>3572.996892</td>\n",
       "      <td>2064.845622</td>\n",
       "      <td>0.865644</td>\n",
       "      <td>2.348680</td>\n",
       "      <td>1.194248</td>\n",
       "      <td>2.655033</td>\n",
       "      <td>1.460307</td>\n",
       "      <td>2.566234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3576.554741</td>\n",
       "      <td>2067.650210</td>\n",
       "      <td>0.924510</td>\n",
       "      <td>1.911533</td>\n",
       "      <td>0.685454</td>\n",
       "      <td>2.356668</td>\n",
       "      <td>2.370724</td>\n",
       "      <td>2.985399</td>\n",
       "      <td>3566.896197</td>\n",
       "      <td>...</td>\n",
       "      <td>32.993621</td>\n",
       "      <td>18.821511</td>\n",
       "      <td>3601.147756</td>\n",
       "      <td>2086.525780</td>\n",
       "      <td>2.441740</td>\n",
       "      <td>10.196956</td>\n",
       "      <td>3.024007</td>\n",
       "      <td>9.499536</td>\n",
       "      <td>39.849476</td>\n",
       "      <td>23.402449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3572.824268</td>\n",
       "      <td>2065.900620</td>\n",
       "      <td>1.184969</td>\n",
       "      <td>2.767634</td>\n",
       "      <td>1.088137</td>\n",
       "      <td>1.876419</td>\n",
       "      <td>1.604564</td>\n",
       "      <td>2.865665</td>\n",
       "      <td>3565.456852</td>\n",
       "      <td>...</td>\n",
       "      <td>28.386048</td>\n",
       "      <td>33.101221</td>\n",
       "      <td>3614.482208</td>\n",
       "      <td>2125.359393</td>\n",
       "      <td>10.478644</td>\n",
       "      <td>24.932313</td>\n",
       "      <td>5.481507</td>\n",
       "      <td>24.672041</td>\n",
       "      <td>35.365792</td>\n",
       "      <td>42.331624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5760 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  AF3 delta std  AF3 delta m  AF3 theta std  AF3 theta m  \\\n",
       "634     1.0    3570.358043  2063.710533       0.456885     3.249995   \n",
       "519     2.0    3572.012160  2064.363908       1.276283     2.241194   \n",
       "2660    1.0    3577.105212  2066.827754       0.934807     2.149105   \n",
       "2831    0.0    3570.545677  2063.521648       1.498312     2.469780   \n",
       "917     2.0    3570.268998  2062.539180       1.192891     2.941243   \n",
       "...     ...            ...          ...            ...          ...   \n",
       "3290    1.0    3568.423670  2063.099248       1.897790     3.728823   \n",
       "4834    0.0    3576.455470  2067.504612       0.819413     2.076764   \n",
       "1348    0.0    3576.454303  2067.954953       0.882673     2.871386   \n",
       "5021    0.0    3576.554741  2067.650210       0.924510     1.911533   \n",
       "1852    2.0    3572.824268  2065.900620       1.184969     2.767634   \n",
       "\n",
       "      AF3 alpha std  AF3 alpha m  AF3 beta std  AF3 beta m  F7 delta std  ...  \\\n",
       "634        0.904365     2.133026      2.139093    3.209357   3568.120212  ...   \n",
       "519        0.817629     2.037404      3.483975    2.982528   3567.117078  ...   \n",
       "2660       0.307708     1.416313      1.622345    3.011557   3566.396533  ...   \n",
       "2831       0.672349     1.436351      1.690035    2.344049   3566.263726  ...   \n",
       "917        0.585210     1.807655      1.773141    2.250589   3570.684256  ...   \n",
       "...             ...          ...           ...         ...           ...  ...   \n",
       "3290       1.304186     1.854353      1.366575    2.546458   3563.560922  ...   \n",
       "4834       0.262696     1.020132      2.796766    2.571867   3569.442445  ...   \n",
       "1348       0.642941     2.006386      1.854039    3.081949   3569.404934  ...   \n",
       "5021       0.685454     2.356668      2.370724    2.985399   3566.896197  ...   \n",
       "1852       1.088137     1.876419      1.604564    2.865665   3565.456852  ...   \n",
       "\n",
       "      F8 beta std  F8 beta m  AF4 delta std  AF4 delta m  AF4 theta std  \\\n",
       "634     28.690691  40.909131    3649.644216  2123.882552       6.433752   \n",
       "519     68.654852  37.173007    3607.344422  2112.397644      10.002576   \n",
       "2660    19.997132  26.721568    3643.312676  2116.121387       3.414466   \n",
       "2831     1.933751   1.780409    3569.917242  2062.488143       1.718757   \n",
       "917      1.990175   1.542020    3569.966082  2062.837023       0.546132   \n",
       "...           ...        ...            ...          ...            ...   \n",
       "3290    36.551948  66.931186    3725.210509  2180.197439       8.820788   \n",
       "4834     1.147571   1.612922    3573.836239  2065.730532       0.662093   \n",
       "1348     1.127120   2.103345    3572.996892  2064.845622       0.865644   \n",
       "5021    32.993621  18.821511    3601.147756  2086.525780       2.441740   \n",
       "1852    28.386048  33.101221    3614.482208  2125.359393      10.478644   \n",
       "\n",
       "      AF4 theta m  AF4 alpha std  AF4 alpha m  AF4 beta std  AF4 beta m  \n",
       "634     16.377331      12.937765    18.813944     33.382509   48.405477  \n",
       "519     20.026195       4.766066    12.693254     80.381629   42.664033  \n",
       "2660     9.414864       6.781557    13.850787     25.237995   31.099147  \n",
       "2831     2.002083       0.722192     1.146630      1.221092    1.732873  \n",
       "917      1.499412       0.965567     1.577828      1.143104    1.852612  \n",
       "...           ...            ...          ...           ...         ...  \n",
       "3290    38.012788      19.601233    29.431054     38.559351   67.470041  \n",
       "4834     1.449532       0.325079     0.907729      1.947072    2.149902  \n",
       "1348     2.348680       1.194248     2.655033      1.460307    2.566234  \n",
       "5021    10.196956       3.024007     9.499536     39.849476   23.402449  \n",
       "1852    24.932313       5.481507    24.672041     35.365792   42.331624  \n",
       "\n",
       "[5760 rows x 113 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I want to work some sample of that dataset\n",
    "data_sample = data.sample(frac=1)# In this case it is 100% data randomly\n",
    "#fraction\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance in random forest\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=3)\n",
    "selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.fit(data_sample)\n",
    "\n",
    "getSupport = selector.get_support()\n",
    "print(getSupport.shape)\n",
    "getSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Trim_data_sample-> (78,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['AF3 delta std', 'AF3 delta m', 'F7 delta std', 'F3 delta std',\n",
       "       'F3 delta m', 'F3 theta std', 'F3 theta m', 'F3 alpha std',\n",
       "       'F3 alpha m', 'F3 beta std', 'F3 beta m', 'FC5 delta std',\n",
       "       'FC5 delta m', 'T7 delta std', 'T7 delta m', 'P7 delta std',\n",
       "       'P7 delta m', 'P7 theta std', 'P7 theta m', 'P7 alpha std',\n",
       "       'P7 alpha m', 'P7 beta std', 'P7 beta m', 'O1 delta std', 'O1 delta m',\n",
       "       'O1 beta std', 'O1 beta m', 'O2 delta std', 'O2 delta m',\n",
       "       'O2 theta std', 'O2 theta m', 'O2 alpha std', 'O2 alpha m',\n",
       "       'O2 beta std', 'O2 beta m', 'P8 delta std', 'P8 delta m', 'P8 theta m',\n",
       "       'P8 alpha m', 'P8 beta std', 'P8 beta m', 'T8 delta std', 'T8 delta m',\n",
       "       'T8 theta std', 'T8 theta m', 'T8 alpha std', 'T8 alpha m',\n",
       "       'T8 beta std', 'T8 beta m', 'FC6 delta std', 'FC6 delta m',\n",
       "       'FC6 theta std', 'FC6 theta m', 'FC6 alpha std', 'FC6 alpha m',\n",
       "       'FC6 beta std', 'FC6 beta m', 'F4 delta std', 'F4 delta m',\n",
       "       'F4 theta m', 'F4 alpha m', 'F4 beta m', 'F8 delta std', 'F8 delta_m',\n",
       "       'F8 theta std', 'F8 theta m', 'F8 alpha std', 'F8 alpha m',\n",
       "       'F8 beta std', 'F8 beta m', 'AF4 delta std', 'AF4 delta m',\n",
       "       'AF4 theta std', 'AF4 theta m', 'AF4 alpha std', 'AF4 alpha m',\n",
       "       'AF4 beta std', 'AF4 beta m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample_col = data_sample.columns[getSupport]\n",
    "print(\"The shape of Trim_data_sample->\",data_sample_col.shape)\n",
    "data_sample_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get features which have the variance less than the set threshold value using list comprehension\n",
    "selected_cols = [column for column in data_sample.columns if column not in data_sample_col ]\n",
    "len(selected_cols)# the length of the list is 35 (the false cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       AF3 delta std  AF3 delta m  F7 delta std  F3 delta std   F3 delta m  \\\n",
       "634     3570.358043  2063.710533   3568.120212   3661.870396  2134.110986   \n",
       "519     3572.012160  2064.363908   3567.117078   3588.063911  2076.057184   \n",
       "2660    3577.105212  2066.827754   3566.396533   3590.737435  2097.404621   \n",
       "2831    3570.545677  2063.521648   3566.263726   3570.871615  2066.042491   \n",
       "917     3570.268998  2062.539180   3570.684256   3565.142304  2073.996762   \n",
       "...             ...          ...           ...           ...          ...   \n",
       "3290    3568.423670  2063.099248   3563.560922   3721.781859  2177.507069   \n",
       "4834    3576.455470  2067.504612   3569.442445   3572.345754  2073.846582   \n",
       "1348    3576.454303  2067.954953   3569.404934   3574.974605  2069.329257   \n",
       "5021    3576.554741  2067.650210   3566.896197   3636.309502  2120.004145   \n",
       "1852    3572.824268  2065.900620   3565.456852   3645.112257  2142.549705   \n",
       "\n",
       "      F3 theta std  F3 theta m  F3 alpha std  F3 alpha m  F3 beta std  ...  \\\n",
       "634       7.339126   17.925344     12.285667   22.766643    34.783133  ...   \n",
       "519       4.652578   12.183764      6.286567   12.677696    79.059980  ...   \n",
       "2660      5.188524   10.652623      9.798093   16.870319    27.818827  ...   \n",
       "2831      1.058491    4.042843      0.841773    2.395915     1.435452  ...   \n",
       "917       1.119781    4.875970      0.528383    3.431684     0.939851  ...   \n",
       "...            ...         ...           ...         ...          ...  ...   \n",
       "3290      7.343344   39.152753     20.145638   32.934098    38.525474  ...   \n",
       "4834      2.911719    3.258520      1.477600    1.576275     1.559290  ...   \n",
       "1348      1.641351    3.721519      1.240062    3.815580     1.498094  ...   \n",
       "5021      2.226034   13.568594      4.856125    9.009248    41.845299  ...   \n",
       "1852      8.616149   26.430938      8.260779   26.548042    39.092764  ...   \n",
       "\n",
       "      F8 beta std  F8 beta m  AF4 delta std  AF4 delta m  AF4 theta std  \\\n",
       "634     28.690691  40.909131    3649.644216  2123.882552       6.433752   \n",
       "519     68.654852  37.173007    3607.344422  2112.397644      10.002576   \n",
       "2660    19.997132  26.721568    3643.312676  2116.121387       3.414466   \n",
       "2831     1.933751   1.780409    3569.917242  2062.488143       1.718757   \n",
       "917      1.990175   1.542020    3569.966082  2062.837023       0.546132   \n",
       "...           ...        ...            ...          ...            ...   \n",
       "3290    36.551948  66.931186    3725.210509  2180.197439       8.820788   \n",
       "4834     1.147571   1.612922    3573.836239  2065.730532       0.662093   \n",
       "1348     1.127120   2.103345    3572.996892  2064.845622       0.865644   \n",
       "5021    32.993621  18.821511    3601.147756  2086.525780       2.441740   \n",
       "1852    28.386048  33.101221    3614.482208  2125.359393      10.478644   \n",
       "\n",
       "      AF4 theta m  AF4 alpha std  AF4 alpha m  AF4 beta std  AF4 beta m  \n",
       "634     16.377331      12.937765    18.813944     33.382509   48.405477  \n",
       "519     20.026195       4.766066    12.693254     80.381629   42.664033  \n",
       "2660     9.414864       6.781557    13.850787     25.237995   31.099147  \n",
       "2831     2.002083       0.722192     1.146630      1.221092    1.732873  \n",
       "917      1.499412       0.965567     1.577828      1.143104    1.852612  \n",
       "...           ...            ...          ...           ...         ...  \n",
       "3290    38.012788      19.601233    29.431054     38.559351   67.470041  \n",
       "4834     1.449532       0.325079     0.907729      1.947072    2.149902  \n",
       "1348     2.348680       1.194248     2.655033      1.460307    2.566234  \n",
       "5021    10.196956       3.024007     9.499536     39.849476   23.402449  \n",
       "1852    24.932313       5.481507    24.672041     35.365792   42.331624  \n",
       "\n",
       "[5760 rows x 78 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_DataSet = data_sample.drop(labels=selected_cols, axis=1)\n",
    "Final_DataSet.head  # The data set is now ready to use in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\MachineLearningFiles\\Random_forest_eeg.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MachineLearningFiles/Random_forest_eeg.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# copy the datasample to df dataframe\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MachineLearningFiles/Random_forest_eeg.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m Final_DataSet\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/MachineLearningFiles/Random_forest_eeg.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mClass\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MachineLearningFiles/Random_forest_eeg.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MachineLearningFiles/Random_forest_eeg.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Train-test split\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Class'"
     ]
    }
   ],
   "source": [
    "# copy the datasample to df dataframe\n",
    "df = Final_DataSet.copy()\n",
    "\n",
    "y = df['Class'].copy()\n",
    "X = data_sample.drop('Class', axis=1)\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
       "                       n_estimators=120)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
       "                       n_estimators=120)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       n_estimators=120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForestClassifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "mdl = RandomForestClassifier(n_estimators=120,class_weight='balanced', criterion='entropy',)#class_weight='balanced', criterion='entropy',\n",
    "mdl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.28125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.score(X_test,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter Tuning\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_dict = {\n",
    "#     \"criterion\":[\"gini\",\"entropy\"],\n",
    "#     \"max_depth\":[1,2,3,4,5,6,7,8,None],\n",
    "#     \"class_weight\": ['balanced', 'balanced_subsample',None],\n",
    "#     \"max_features\":['sqrt', 'log2']\n",
    "\n",
    "# }\n",
    "\n",
    "# # K fold corss validation\n",
    "# grid = GridSearchCV(mdl,param_grid=param_dict, cv=5, n_jobs=-1)# CV = cross validation\n",
    "# '''n_jobs = -1 means the n_jobs parameter can be used to distribute and exploit all the CPUs available in the local computer'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance in random forest\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# selector = VarianceThreshold(threshold=3)\n",
    "# selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.fit(X_train)\n",
    "selector.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3 delta std</th>\n",
       "      <th>AF3 delta m</th>\n",
       "      <th>F7 delta std</th>\n",
       "      <th>F3 delta std</th>\n",
       "      <th>F3 delta m</th>\n",
       "      <th>F3 theta std</th>\n",
       "      <th>F3 theta m</th>\n",
       "      <th>F3 alpha std</th>\n",
       "      <th>F3 alpha m</th>\n",
       "      <th>F3 beta std</th>\n",
       "      <th>...</th>\n",
       "      <th>F8 beta std</th>\n",
       "      <th>F8 beta m</th>\n",
       "      <th>AF4 delta std</th>\n",
       "      <th>AF4 delta m</th>\n",
       "      <th>AF4 theta std</th>\n",
       "      <th>AF4 theta m</th>\n",
       "      <th>AF4 alpha std</th>\n",
       "      <th>AF4 alpha m</th>\n",
       "      <th>AF4 beta std</th>\n",
       "      <th>AF4 beta m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>3572.027136</td>\n",
       "      <td>2064.146180</td>\n",
       "      <td>3563.995445</td>\n",
       "      <td>3621.243626</td>\n",
       "      <td>2120.715055</td>\n",
       "      <td>15.859108</td>\n",
       "      <td>42.858308</td>\n",
       "      <td>10.578798</td>\n",
       "      <td>52.130701</td>\n",
       "      <td>50.646608</td>\n",
       "      <td>...</td>\n",
       "      <td>50.584956</td>\n",
       "      <td>71.693362</td>\n",
       "      <td>3619.760598</td>\n",
       "      <td>2123.911556</td>\n",
       "      <td>17.870220</td>\n",
       "      <td>40.598388</td>\n",
       "      <td>10.009160</td>\n",
       "      <td>55.196876</td>\n",
       "      <td>50.735310</td>\n",
       "      <td>70.211586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>3569.682868</td>\n",
       "      <td>2064.401543</td>\n",
       "      <td>3565.860702</td>\n",
       "      <td>3659.928334</td>\n",
       "      <td>2170.027874</td>\n",
       "      <td>7.891360</td>\n",
       "      <td>17.678841</td>\n",
       "      <td>9.557791</td>\n",
       "      <td>17.191556</td>\n",
       "      <td>30.366976</td>\n",
       "      <td>...</td>\n",
       "      <td>21.791447</td>\n",
       "      <td>33.420930</td>\n",
       "      <td>3646.675636</td>\n",
       "      <td>2142.483930</td>\n",
       "      <td>6.693199</td>\n",
       "      <td>21.274994</td>\n",
       "      <td>7.185486</td>\n",
       "      <td>13.158422</td>\n",
       "      <td>26.523305</td>\n",
       "      <td>40.190928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>3572.961498</td>\n",
       "      <td>2065.053021</td>\n",
       "      <td>3564.634710</td>\n",
       "      <td>3561.306244</td>\n",
       "      <td>2085.199516</td>\n",
       "      <td>15.403869</td>\n",
       "      <td>21.401615</td>\n",
       "      <td>7.074566</td>\n",
       "      <td>32.828161</td>\n",
       "      <td>57.511603</td>\n",
       "      <td>...</td>\n",
       "      <td>51.828988</td>\n",
       "      <td>50.625223</td>\n",
       "      <td>3547.851566</td>\n",
       "      <td>2101.148405</td>\n",
       "      <td>13.191891</td>\n",
       "      <td>23.220265</td>\n",
       "      <td>8.508776</td>\n",
       "      <td>35.569543</td>\n",
       "      <td>56.558038</td>\n",
       "      <td>55.376266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3575.384840</td>\n",
       "      <td>2065.941357</td>\n",
       "      <td>3572.243896</td>\n",
       "      <td>3597.151941</td>\n",
       "      <td>2098.945768</td>\n",
       "      <td>8.400345</td>\n",
       "      <td>15.755961</td>\n",
       "      <td>4.379878</td>\n",
       "      <td>11.169033</td>\n",
       "      <td>29.876394</td>\n",
       "      <td>...</td>\n",
       "      <td>22.051974</td>\n",
       "      <td>25.120462</td>\n",
       "      <td>3613.682407</td>\n",
       "      <td>2104.785778</td>\n",
       "      <td>5.299796</td>\n",
       "      <td>13.524333</td>\n",
       "      <td>6.242915</td>\n",
       "      <td>9.177542</td>\n",
       "      <td>27.259060</td>\n",
       "      <td>30.242592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>3574.205508</td>\n",
       "      <td>2065.277392</td>\n",
       "      <td>3570.944583</td>\n",
       "      <td>3601.618186</td>\n",
       "      <td>2090.047227</td>\n",
       "      <td>6.401163</td>\n",
       "      <td>16.668838</td>\n",
       "      <td>11.274900</td>\n",
       "      <td>22.755214</td>\n",
       "      <td>23.351923</td>\n",
       "      <td>...</td>\n",
       "      <td>18.290433</td>\n",
       "      <td>30.323079</td>\n",
       "      <td>3615.558427</td>\n",
       "      <td>2113.553614</td>\n",
       "      <td>3.678107</td>\n",
       "      <td>12.498010</td>\n",
       "      <td>7.530224</td>\n",
       "      <td>19.905400</td>\n",
       "      <td>21.797580</td>\n",
       "      <td>36.113382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>3570.167319</td>\n",
       "      <td>2064.918633</td>\n",
       "      <td>3569.959183</td>\n",
       "      <td>3590.102293</td>\n",
       "      <td>2078.167598</td>\n",
       "      <td>1.597232</td>\n",
       "      <td>3.131035</td>\n",
       "      <td>0.504126</td>\n",
       "      <td>2.334475</td>\n",
       "      <td>1.592381</td>\n",
       "      <td>...</td>\n",
       "      <td>1.330798</td>\n",
       "      <td>1.862323</td>\n",
       "      <td>3572.337915</td>\n",
       "      <td>2064.853002</td>\n",
       "      <td>0.346046</td>\n",
       "      <td>1.985277</td>\n",
       "      <td>0.704804</td>\n",
       "      <td>1.624659</td>\n",
       "      <td>1.280812</td>\n",
       "      <td>2.110191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>3576.981004</td>\n",
       "      <td>2067.108280</td>\n",
       "      <td>3570.553459</td>\n",
       "      <td>3571.111629</td>\n",
       "      <td>2065.394705</td>\n",
       "      <td>1.818140</td>\n",
       "      <td>2.745309</td>\n",
       "      <td>1.370857</td>\n",
       "      <td>4.688130</td>\n",
       "      <td>1.163745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407487</td>\n",
       "      <td>2.108329</td>\n",
       "      <td>3573.382650</td>\n",
       "      <td>2064.580759</td>\n",
       "      <td>0.234698</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.603232</td>\n",
       "      <td>1.723646</td>\n",
       "      <td>1.991662</td>\n",
       "      <td>2.290068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>3572.407635</td>\n",
       "      <td>2064.379259</td>\n",
       "      <td>3570.251588</td>\n",
       "      <td>3577.397058</td>\n",
       "      <td>2077.453547</td>\n",
       "      <td>3.190318</td>\n",
       "      <td>9.283449</td>\n",
       "      <td>7.003852</td>\n",
       "      <td>17.172073</td>\n",
       "      <td>31.246098</td>\n",
       "      <td>...</td>\n",
       "      <td>24.865313</td>\n",
       "      <td>33.106138</td>\n",
       "      <td>3583.494168</td>\n",
       "      <td>2079.471706</td>\n",
       "      <td>5.053676</td>\n",
       "      <td>14.337757</td>\n",
       "      <td>7.653187</td>\n",
       "      <td>13.584068</td>\n",
       "      <td>28.868215</td>\n",
       "      <td>40.853282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>3574.961766</td>\n",
       "      <td>2065.691398</td>\n",
       "      <td>3563.803154</td>\n",
       "      <td>3621.043623</td>\n",
       "      <td>2115.600783</td>\n",
       "      <td>7.721305</td>\n",
       "      <td>20.710122</td>\n",
       "      <td>13.859956</td>\n",
       "      <td>31.147344</td>\n",
       "      <td>39.934168</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720565</td>\n",
       "      <td>39.011129</td>\n",
       "      <td>3620.236549</td>\n",
       "      <td>2114.034665</td>\n",
       "      <td>7.279527</td>\n",
       "      <td>17.518312</td>\n",
       "      <td>11.505987</td>\n",
       "      <td>28.667273</td>\n",
       "      <td>36.891866</td>\n",
       "      <td>48.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>3575.152985</td>\n",
       "      <td>2068.057738</td>\n",
       "      <td>3568.203523</td>\n",
       "      <td>3606.684191</td>\n",
       "      <td>2100.895105</td>\n",
       "      <td>4.221287</td>\n",
       "      <td>22.204062</td>\n",
       "      <td>3.915412</td>\n",
       "      <td>16.931938</td>\n",
       "      <td>26.261999</td>\n",
       "      <td>...</td>\n",
       "      <td>19.116023</td>\n",
       "      <td>27.637071</td>\n",
       "      <td>3596.847031</td>\n",
       "      <td>2088.321731</td>\n",
       "      <td>5.770563</td>\n",
       "      <td>19.914192</td>\n",
       "      <td>6.093615</td>\n",
       "      <td>15.497345</td>\n",
       "      <td>24.212486</td>\n",
       "      <td>32.497998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AF3 delta std  AF3 delta m  F7 delta std  F3 delta std   F3 delta m  \\\n",
       "3076    3572.027136  2064.146180   3563.995445   3621.243626  2120.715055   \n",
       "2724    3569.682868  2064.401543   3565.860702   3659.928334  2170.027874   \n",
       "2366    3572.961498  2065.053021   3564.634710   3561.306244  2085.199516   \n",
       "308     3575.384840  2065.941357   3572.243896   3597.151941  2098.945768   \n",
       "3622    3574.205508  2065.277392   3570.944583   3601.618186  2090.047227   \n",
       "...             ...          ...           ...           ...          ...   \n",
       "3284    3570.167319  2064.918633   3569.959183   3590.102293  2078.167598   \n",
       "859     3576.981004  2067.108280   3570.553459   3571.111629  2065.394705   \n",
       "2297    3572.407635  2064.379259   3570.251588   3577.397058  2077.453547   \n",
       "2136    3574.961766  2065.691398   3563.803154   3621.043623  2115.600783   \n",
       "820     3575.152985  2068.057738   3568.203523   3606.684191  2100.895105   \n",
       "\n",
       "      F3 theta std  F3 theta m  F3 alpha std  F3 alpha m  F3 beta std  ...  \\\n",
       "3076     15.859108   42.858308     10.578798   52.130701    50.646608  ...   \n",
       "2724      7.891360   17.678841      9.557791   17.191556    30.366976  ...   \n",
       "2366     15.403869   21.401615      7.074566   32.828161    57.511603  ...   \n",
       "308       8.400345   15.755961      4.379878   11.169033    29.876394  ...   \n",
       "3622      6.401163   16.668838     11.274900   22.755214    23.351923  ...   \n",
       "...            ...         ...           ...         ...          ...  ...   \n",
       "3284      1.597232    3.131035      0.504126    2.334475     1.592381  ...   \n",
       "859       1.818140    2.745309      1.370857    4.688130     1.163745  ...   \n",
       "2297      3.190318    9.283449      7.003852   17.172073    31.246098  ...   \n",
       "2136      7.721305   20.710122     13.859956   31.147344    39.934168  ...   \n",
       "820       4.221287   22.204062      3.915412   16.931938    26.261999  ...   \n",
       "\n",
       "      F8 beta std  F8 beta m  AF4 delta std  AF4 delta m  AF4 theta std  \\\n",
       "3076    50.584956  71.693362    3619.760598  2123.911556      17.870220   \n",
       "2724    21.791447  33.420930    3646.675636  2142.483930       6.693199   \n",
       "2366    51.828988  50.625223    3547.851566  2101.148405      13.191891   \n",
       "308     22.051974  25.120462    3613.682407  2104.785778       5.299796   \n",
       "3622    18.290433  30.323079    3615.558427  2113.553614       3.678107   \n",
       "...           ...        ...            ...          ...            ...   \n",
       "3284     1.330798   1.862323    3572.337915  2064.853002       0.346046   \n",
       "859      1.407487   2.108329    3573.382650  2064.580759       0.234698   \n",
       "2297    24.865313  33.106138    3583.494168  2079.471706       5.053676   \n",
       "2136    29.720565  39.011129    3620.236549  2114.034665       7.279527   \n",
       "820     19.116023  27.637071    3596.847031  2088.321731       5.770563   \n",
       "\n",
       "      AF4 theta m  AF4 alpha std  AF4 alpha m  AF4 beta std  AF4 beta m  \n",
       "3076    40.598388      10.009160    55.196876     50.735310   70.211586  \n",
       "2724    21.274994       7.185486    13.158422     26.523305   40.190928  \n",
       "2366    23.220265       8.508776    35.569543     56.558038   55.376266  \n",
       "308     13.524333       6.242915     9.177542     27.259060   30.242592  \n",
       "3622    12.498010       7.530224    19.905400     21.797580   36.113382  \n",
       "...           ...            ...          ...           ...         ...  \n",
       "3284     1.985277       0.704804     1.624659      1.280812    2.110191  \n",
       "859      0.828384       0.603232     1.723646      1.991662    2.290068  \n",
       "2297    14.337757       7.653187    13.584068     28.868215   40.853282  \n",
       "2136    17.518312      11.505987    28.667273     36.891866   48.954545  \n",
       "820     19.914192       6.093615    15.497345     24.212486   32.497998  \n",
       "\n",
       "[4608 rows x 78 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.columns[selector.get_support()].shape)\n",
    "abc = X_train.drop(X_train.columns[selector.get_support()], axis=1)\n",
    "abc.columns\n",
    "X_train_trim = X_train.drop(abc.columns, axis=1)\n",
    "X_train_trim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
       "                       n_estimators=120)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
       "                       n_estimators=120)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       n_estimators=120)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=120,class_weight='balanced', criterion='entropy',)#class_weight='balanced', criterion='entropy',\n",
    "mdl.fit(X_train_trim,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AF3 alpha m\n- AF3 alpha std\n- AF3 beta m\n- AF3 beta std\n- AF3 theta m\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Python_Files\\MachineLearning\\Random_forest_eeg.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Python_Files/MachineLearning/Random_forest_eeg.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mdl\u001b[39m.\u001b[39;49mscore(X_test,y_test)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    502\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 506\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AF3 alpha m\n- AF3 alpha std\n- AF3 beta m\n- AF3 beta std\n- AF3 theta m\n- ...\n"
     ]
    }
   ],
   "source": [
    "mdl.score(X_test,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[339,  19,  19],\n",
       "       [ 18, 342,  24],\n",
       "       [ 16,  20, 355]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I use confusion matrix to measure the performance of classification models,\n",
    "#which aim to predict a categorical label for each input instance.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting in graph..\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "plt.figure(figsize=(10,7))\n",
    "sbn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
